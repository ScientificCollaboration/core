{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import schedule\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from h3 import h3\n",
    "\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "\n",
    " \n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "import requests \n",
    "import neptune\n",
    "#app = FastAPI()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dfcsv1 = pd.read_csv('output_v88.csv', sep=';', nrows=10000)\n",
    "dfcsv2 = dfcsv1.fillna(0)\n",
    "pd.set_option('display.max_columns', None)\n",
    "X = dfcsv2.drop(columns=['category'])\n",
    "Y = dfcsv2['category']\n",
    "result =  pd.concat([X, Y.reindex(X.index)], axis=1)\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    "\n",
    "\n",
    "def train(train):\n",
    "\ttrain = asarray(train)\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = OneVsRestClassifier(XGBClassifier()) #RandomForestClassifier(n_estimators=100,max_depth=20, random_state=0)#XGBRegressor(objective='reg:squarederror', n_estimators=1000,tree_method='gpu_hist')\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\tjoblib.dump(model,'dd.joblib', compress=0, protocol=None, cache_size=None)\n",
    "\treturn model,train\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(testX):\n",
    "\t# transform list into array\n",
    "\t#train = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\t#trainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\t#model = RandomForestClassifier(n_estimators=100,max_depth=20, random_state=0)#XGBRegressor(objective='reg:squarederror', n_estimators=1000,tree_method='gpu_hist')\n",
    "\t#model.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\t#joblib.dump(model, 'dd.joblib', compress=0, protocol=None, cache_size=None)\n",
    "\t#joblib.dump(model, Path(BASE_DIR)).joinpath(f\"{dfcsv2}.joblib\")\n",
    "\t#model_file = Path(BASE_DIR).joinpath(f\"{dfcsv2}.joblib\")\n",
    "\n",
    "\tmodel = joblib.load('dd.joblib',mmap_mode = 'r+' )\n",
    "\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\n",
    "\t## filename = 'finalized_model.sav'\n",
    "\t## pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "\t# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\t# result1 = loaded_model.score(X,Y)\n",
    "\t\n",
    "\treturn yhat[0] #,result1\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\t\n",
    "\t#model = joblib.load('dd.joblib',mmap_mode = 'r+' )\n",
    "\t#yhat = model.predict(asarray([testX]))\n",
    "\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\t\n",
    "\treturn error, test[:, -1], predictions\n",
    "\n",
    "dataset = result#pd.read_csv('table_orders.csv')\n",
    "#dataset = dataset.set_index('time')        \n",
    "cols = list(dataset)\n",
    "    #series = dataset[cols] \n",
    "# split dataset\n",
    "V = dataset.values     \n",
    "data = series_to_supervised(V, n_in=1)\n",
    "train(data[0:8000]) # - переключение!!!!!!!!!!!!!!!!\n",
    "mae, y, yhat = walk_forward_validation(data[8000:10000], 48)\n",
    "\n",
    "def convert(yhat):\n",
    "    output = {\"prediction\":yhat}\n",
    "    \n",
    "    return output\n",
    "\n",
    "run['prediction'] = walk_forward_validation(data[80000:100000], 48)\n",
    "\n",
    "#response = requests.post('http://127.0.0.1:8008/predict', json=convert(yhat))\n",
    "#print(response.content)\n",
    "pd.DataFrame(yhat).to_csv('pred.csv')  \n",
    "\n",
    "# File\n",
    "run[\"pred_dataset\"].track_files(\"./pred.csv\")\n",
    "# You can also upload plot objects directly\n",
    "\n",
    "print(result)\n",
    "print('MAE: %.3f' % mae)\n",
    "\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "print('Column Number : ')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
